---
title: "Homework 6 solutions"
author: "Rio Yan"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
library(ggcorrplot)
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 9,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

Read in the data.
```{r, message=FALSE}
homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ","),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest" ~ 0,
      disposition == "Closed by arrest" ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa,AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city.

```{r, echo=FALSE}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore,MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digit = 3)
```


Try this across cities.

```{r}
models_results_df =
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex,
    data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))
```

```{r}
models_results_df %>% 
  filter(term == "victim_raceWhite") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

__Comment__: 
We can see that Tampa, FL has the lowest OR with small 95% CI range and Boston,MA has the highest and has the largest 95% CI range. All the OR are above 0, meaning that comparing to black population, when victim is white, the cases have a higher chance of being solved. 



## Problem 2

Find some residuals

```{r, message=FALSE}
baby_df = 
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = factor(babysex), #convert numeric to factor
    frace = factor(frace), #convert numeric to factor
    malform = factor(malform), #convert numeric to factor
    mrace = factor(mrace) #convert numeric to factor
  ) 

baby_df %>% 
  sapply(function(na) sum(is.na(na))) 
#check if there is NA: no NAs
```

Model selection (stepwise regression)

```{r}
test_model = lm(bwt ~ ., data = baby_df)
step(test_model, direction = 'backward')
```

Using stepwise regression to identify which models, because Lower AIC values indicate a better-fit model, so I choose the last model with babysex+ bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken.


fit a model

```{r}
model_fit = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = baby_df)

summary(model_fit)
```

final model is bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken and F-test shows significant. 


plot residual

```{r, message=FALSE}
baby_df %>% 
  modelr::add_residuals(model_fit) %>% 
  modelr::add_predictions(model_fit) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point(alpha = 0.4) +
  labs(
    title = "Residuals against fitted value",
    x = "Fitted value",
    y = "Residuals"
  )
```

Overall, most of the residuals are centered around 0, meaning our model's assumption of normality holds. However, when the prediction is less than 2000 or greater than 4000, residuals are not normally distributed. 


```{r}
cv_df =
  crossv_mc(baby_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df = 
  cv_df %>% 
  mutate(
    model_fit = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    model_1 = map(train, ~lm(bwt ~blength + gaweeks, data = .x)),
    model_2 = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_fit = map2_dbl(model_fit, test, ~rmse(model = .x, data = .y)),
    rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y))
  )
```

plot prediction error for each models

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(title = "Compare fitted model to other model",
       x = "Model",
       y = "RMSE")
```



compare models

`model_fit = bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks+ mheight + mrace + parity + ppwt + smoken`

`model_1 = bwt ~ blength + gaweeks`

`model_2 = bwt ~ bhead * blength * babysex`


From the graph we can see that the model that i fitted with babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken shows higer predictive accuracy, suggesting a better model out of the three. Model 2 is the second best, this may be because adding too many variable increases the degrees of value and increases it's predictive accuracy. 


## Problem 3

import data

```{r, message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


Bootstrapping

For $\hat{r^2}$

```{r}
r_sq = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)
  ) %>% 
  select(-strap, -models) %>% 
  unnest(results) 

#distribution
r_sq %>% 
  ggplot(aes(x = r.squared)) + geom_density() +
  labs(
    title = "Distribution of R Squared"
  )


#95% CI
r2_ci_lower = quantile(pull(r_sq, r.squared), 0.025)
r2_ci_upper = quantile(pull(r_sq, r.squared), 0.975)
```


For $log(\hat{\beta_0} * \hat{\beta_1})$

```{r}
betas = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>%
  mutate(
    term = str_replace(term,"\\(Intercept\\)","beta0"),
    term = str_replace(term,"tmin","beta1")
  ) %>% 
  spread(term, estimate) %>%
  group_by(.id) %>%
  summarise_all(na.omit) %>% 
  mutate(
    beta_c = log(beta0 * beta1)
  ) 


  toDelete = seq(1, nrow(betas), 2)
betas = betas[ toDelete ,]
  
  
#distribution
betas %>% 
  ggplot(aes(x = beta_c)) + geom_density() +
  labs(
    title = "Distribution of Log Estimates"
  )

#95% CI
beta_ci_lower = quantile(pull(betas,beta_c), 0.025)
beta_ci_upper = quantile(pull(betas,beta_c), 0.975)
```


The distributions of $\hat{r^2}$ and $log(\hat{\beta_0} * \hat{\beta_1})$ using bootstrap seem to be following a normal distribution with $\hat{r^2}$s distribution centered around 0.915 and $log(\hat{\beta_0} * \hat{\beta_1})$ centered around 2.02. Both are slightly left skewed. $\hat{r^2}$ 95%CI is (`r r2_ci_lower`, `r r2_ci_upper`) and $log(\hat{\beta_0} * \hat{\beta_1})$ 95%CI is (`r beta_ci_lower`, `r beta_ci_upper`). 